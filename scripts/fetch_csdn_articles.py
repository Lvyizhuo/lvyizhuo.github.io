#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSDNåšå®¢æ–‡ç« æŠ“å–è„šæœ¬
ä½¿ç”¨ RSS Feed æŠ“å–æŒ‡å®šCSDNåšå®¢çš„æ–‡ç« åˆ—è¡¨å¹¶ä¿å­˜ä¸ºYAMLæ ¼å¼
ä½œè€…: GitHub Actions Bot
"""

import requests
from bs4 import BeautifulSoup
import yaml
import re
from datetime import datetime
import time
import os
import xml.etree.ElementTree as ET

# CSDNåšå®¢é…ç½®
CSDN_USERNAME = "Lvyizhuo"
CSDN_BLOG_URL = f"https://blog.csdn.net/{CSDN_USERNAME}"
CSDN_RSS_URL = f"https://blog.csdn.net/{CSDN_USERNAME}/rss/list"
OUTPUT_FILE = "_data/csdn_posts.yml"

# è¯·æ±‚å¤´ - RSS è¯·æ±‚æ›´ç®€å•
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (compatible; RSS Reader/1.0)',
    'Accept': 'application/rss+xml, application/xml, text/xml, */*',
}


def fetch_article_list_from_rss():
    """
    ä» RSS Feed æŠ“å–CSDNåšå®¢æ–‡ç« åˆ—è¡¨
    
    Returns:
        articles: æ–‡ç« åˆ—è¡¨ï¼Œæ¯ç¯‡æ–‡ç« åŒ…å«æ ‡é¢˜ã€é“¾æ¥ã€æ—¥æœŸã€æ‘˜è¦ç­‰ä¿¡æ¯
    """
    articles = []
    
    print(f"ğŸ” å¼€å§‹ä» RSS æŠ“å–CSDNåšå®¢: {CSDN_RSS_URL}")
    
    max_retries = 3
    
    for retry in range(max_retries):
        try:
            print(f"ğŸ“¡ æ­£åœ¨è¯·æ±‚ RSS Feed (å°è¯• {retry + 1}/{max_retries})...")
            
            # å‘é€è¯·æ±‚
            response = requests.get(CSDN_RSS_URL, headers=HEADERS, timeout=15)
            response.raise_for_status()
            
            # è§£æ XML
            root = ET.fromstring(response.content)
            
            # RSS 2.0 æ ¼å¼
            items = root.findall('.//item')
            
            if not items:
                print(f"âš ï¸  RSS ä¸­æœªæ‰¾åˆ°æ–‡ç« ...")
                if retry < max_retries - 1:
                    time.sleep((retry + 1) * 3)
                    continue
                else:
                    return []
            
            print(f"âœ… RSS ä¸­æ‰¾åˆ° {len(items)} ç¯‡æ–‡ç« ")
            
            for item in items:
                try:
                    # æå–æ ‡é¢˜
                    title_elem = item.find('title')
                    title = title_elem.text.strip() if title_elem is not None else ''
                    
                    # æå–é“¾æ¥
                    link_elem = item.find('link')
                    link = link_elem.text.strip() if link_elem is not None else ''
                    
                    # æå–å‘å¸ƒæ—¥æœŸ
                    date_elem = item.find('pubDate')
                    date_str = ''
                    if date_elem is not None and date_elem.text:
                        try:
                            # è§£æ RSS æ—¥æœŸæ ¼å¼: "Sat, 25 Jan 2026 14:30:00 GMT"
                            pub_date = datetime.strptime(date_elem.text.strip(), '%a, %d %b %Y %H:%M:%S %Z')
                            date_str = pub_date.strftime('%Y-%m-%d')
                        except:
                            # å¦‚æœè§£æå¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ–‡æœ¬
                            date_str = date_elem.text.strip()[:10]
                    
                    # æå–æè¿°/æ‘˜è¦
                    desc_elem = item.find('description')
                    excerpt = ''
                    if desc_elem is not None and desc_elem.text:
                        # æ¸…ç† HTML æ ‡ç­¾
                        soup = BeautifulSoup(desc_elem.text, 'html.parser')
                        excerpt = soup.get_text().strip()
                        # é™åˆ¶é•¿åº¦
                        if len(excerpt) > 150:
                            excerpt = excerpt[:150] + '...'
                    
                    # æ„å»ºæ–‡ç« æ•°æ®
                    if title and link:
                        article = {
                            'title': title,
                            'link': link,
                            'date': date_str,
                            'excerpt': excerpt,
                            'views': ''  # RSS ä¸­æ²¡æœ‰é˜…è¯»é‡ä¿¡æ¯
                        }
                        articles.append(article)
                    
                except Exception as e:
                    print(f"âš ï¸  è§£ææ–‡ç« æ—¶å‡ºé”™: {str(e)}")
                    continue
            
            break  # æˆåŠŸï¼Œé€€å‡ºé‡è¯•å¾ªç¯
            
        except requests.RequestException as e:
            print(f"âŒ è¯·æ±‚å¤±è´¥ (å°è¯• {retry + 1}/{max_retries}): {str(e)}")
            if retry < max_retries - 1:
                time.sleep((retry + 1) * 5)
            else:
                return []
        except ET.ParseError as e:
            print(f"âŒ XML è§£æé”™è¯¯ (å°è¯• {retry + 1}/{max_retries}): {str(e)}")
            if retry < max_retries - 1:
                time.sleep((retry + 1) * 3)
            else:
                return []
        except Exception as e:
            print(f"âŒ å¤„ç†æ—¶å‡ºé”™ (å°è¯• {retry + 1}/{max_retries}): {str(e)}")
            if retry < max_retries - 1:
                time.sleep((retry + 1) * 3)
            else:
                return []
    
    print(f"\nâœ¨ æ€»å…±æŠ“å–åˆ° {len(articles)} ç¯‡æ–‡ç« ")
    return articles


def fetch_article_list(max_pages=5):
    """
    æŠ“å–CSDNåšå®¢æ–‡ç« åˆ—è¡¨ - ä¿ç•™ç”¨äºå¤‡ç”¨
    ä¼˜å…ˆä½¿ç”¨ RSSï¼Œå¦‚æœå¤±è´¥åˆ™å°è¯•ç½‘é¡µçˆ¬å–
    """
    # é¦–å…ˆå°è¯• RSS
    articles = fetch_article_list_from_rss()
    if articles:
        return articles
    
    print("\nâš ï¸  RSS æ–¹æ³•å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•...")
    
    # å¤‡ç”¨æ–¹æ³•ï¼šç½‘é¡µçˆ¬å–ï¼ˆå¯èƒ½è¢«å°ï¼‰
    # å¤‡ç”¨æ–¹æ³•ï¼šç½‘é¡µçˆ¬å–ï¼ˆå¯èƒ½è¢«å°ï¼‰
    articles = []
    
    print(f"ğŸ” å°è¯•ä»ç½‘é¡µæŠ“å–: {CSDN_BLOG_URL}")
    
    # è¿™é‡Œä¿ç•™åŸæ¥çš„ç½‘é¡µçˆ¬å–ä»£ç ä½œä¸ºå¤‡ç”¨
    # ä½†ä¸€èˆ¬ä¸ä¼šæ‰§è¡Œåˆ°è¿™é‡Œï¼Œå› ä¸º RSS æ›´å¯é 
    
    return articles


def save_to_yaml(articles):
    """
    å°†æ–‡ç« åˆ—è¡¨ä¿å­˜ä¸ºYAMLæ–‡ä»¶
    
    Args:
        articles: æ–‡ç« åˆ—è¡¨
    """
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    
    # æ·»åŠ å…ƒæ•°æ®
    data = {
        'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'total_count': len(articles),
        'articles': articles
    }
    
    # ä¿å­˜ä¸ºYAML
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        yaml.dump(data, f, allow_unicode=True, sort_keys=False, default_flow_style=False)
    
    print(f"ğŸ’¾ æ–‡ç« åˆ—è¡¨å·²ä¿å­˜åˆ°: {OUTPUT_FILE}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("CSDNåšå®¢æ–‡ç« åŒæ­¥å·¥å…·")
    print("=" * 60)
    
    try:
        # æŠ“å–æ–‡ç« 
        articles = fetch_article_list(max_pages=10)
        
        if articles:
            # ä¿å­˜åˆ°YAML
            save_to_yaml(articles)
            print("\nğŸ‰ åŒæ­¥å®Œæˆï¼")
            return 0
        else:
            print("\nâš ï¸  æœªæŠ“å–åˆ°ä»»ä½•æ–‡ç« ")
            return 1
            
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    exit(main())
